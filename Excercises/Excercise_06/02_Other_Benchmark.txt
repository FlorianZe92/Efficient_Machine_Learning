(arm22_pytorch1.10) [fzeidler@fj160 mini_dnn_linear]$ LIBXSMM_TARGET=a64fx OMP_PLACES={0}:48:1 OMP_NUM_THREADS=48 ./build/performance_matmul
running performance tests
here are our dimensions:
  n: 256
  k: 4096
  c: 4096
  bn: 64
  bk: 16
  bc: 128
  nb: 4
  kb: 256
  cb: 32
benchmarking MatmulReluAten..
  repetitions:         208
  duration in seconds: 0.845598
  FP32 GFLOPS:         2112.95
benchmarking MatmulLibxsmm..
  repetitions:         345
  duration in seconds: 1.07922
  FP32 GFLOPS:         2745.98